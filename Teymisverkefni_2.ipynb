{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Teymisverkefni 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqIXTrr03QfY"
      },
      "source": [
        "**Teymisverkefni 2**\n",
        "\n",
        "Í teymisverkefni-2 er markmiðið að læra leikáætlun með því að spila á móti annarri leikáætlun sem er líka að læra (e. both sides are learning). Sjá umræðu í Sutton and Barto (fyrsta kafla) um self-play og tic-tac-toe. \n",
        "\n",
        "Hvert teymi skilar **teymiX.npy** skrá með stefnu $\\pi(s,a)$ þar sem $s$ er skilgreint  með Zobrist hashing (sjá neðar) ásamt læsilegri og auðskiljanlegri útfærslu á reikniriti.\n",
        "\n",
        "Frjálst er að velja \"reinforcement learning\" reiknirit sem við höfum fjallað um í þessari námslotu. Sem dæmi, það má vera TD($0$), MC, TD($\\lambda$), $Q-$learning, SARSA($\\lambda$), expected SARSA($\\lambda$). Svo þarf að spá í hvernig *exploration* er útfært.\n",
        "\n",
        "Áður en þið byrjið skulum við ræða eftirfarandi æfingar úr Sutton og Barto:\n",
        "\n",
        "  1. (Exercise 1.1): **Self-Play** Suppose, instead of playing against a random opponent, the reinforcement learning algorithm described above played against itself, with both sides learning. What do you think would happen in this case? Would it learn a different policy for selecting moves?\n",
        "\n",
        "  2. (Exercise 1.2): **Symmetries** Some Connect-4 positions appear different but are really the same because of symmetries. How might we amend the learning process described above to take advantage of this? In what ways would this change improve the learning process? Now think again. Suppose the opponent did not take advantage of symmetries. In that case, should we? Is it true, then, that symmetrically equivalent positions should necessarily have the same value?\n",
        "\n",
        "  3. Exercise 1.3: **Greedy Play** Suppose the reinforcement learning player was greedy, that is, it always played the move that brought it to the position that it rated the best. Might it learn to play better, or worse, than a nongreedy player? What problems might occur?\n",
        "\n",
        "  4. Exercise 1.4: **Learning from Exploration** Suppose learning updates occurred after all moves, including exploratory moves. If the step-size parameter is appropriately reduced over time (but not the tendency to explore), then the state values would converge to a different set of probabilities. What (conceptually) are the two sets of probabilities computed when we do, and when we do not, learn from exploratory moves? Assuming that we do continue to make exploratory moves, which set of probabilities might be better to learn? Which would result in more wins?\n",
        "\n",
        "  5. *Exercise 1.5*: **Other Improvements** Can you think of other ways to improve the reinforce- ment learning player? Can you think of any better way to solve the Connect-3 problem as posed?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6KO7AsvJezQ"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMGDAjrzJOVt"
      },
      "source": [
        "**Connect-3 a mini version of Connect-4 on a 5x5 board**\n",
        "\n",
        "The following code implements the game Connect-3 on a 5-by-5 board. We will walk through this code in class. I am open for any improvement you may suggest for making the code faster. The Zobrist hashing table is randomly generated using the seed 42. Don't change how we generate the hashed states, I aim to let your policy compete against policies generated by other teams. This final exercise, will be used as input to our discussion on Sutton and Barto's exercise 1.1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMh2R_LSJNtb",
        "outputId": "a0713921-7307-444a-d3de-41370c6a2e70"
      },
      "source": [
        "# two player game (1) versus (2)\n",
        "getotherplayer = lambda p : 3-p # returns the other player\n",
        "# the initial empty board, in matrix board we store legal indices in board[:,-1]\n",
        "def iState(n = 5, m = 5):\n",
        "  return np.zeros((n,m+1), dtype=np.uint16)\n",
        "# perform move for player on board\n",
        "def Action(board, move, player):\n",
        "  if board[move,-2] > 0:\n",
        "    print(\"illegal move \", move, \" for board \", np.flipud(board.T))\n",
        "    raise\n",
        "  else:\n",
        "    board[move,board[move,-1]] = player # place the disc on board\n",
        "    board[move,-1] += 1 # next legal drop\n",
        "  return board\n",
        "# determine if terminal board state, assuming last move was made by player p\n",
        "def terminal(board, p, i, j, n = 5, m = 5):\n",
        "  # Horizontal\n",
        "  t = -min(2, i)\n",
        "  count = 0\n",
        "  while (t <= min(2, n-1-i) and count < 3):\n",
        "    if board[i+t,j] == p:\n",
        "      count += 1\n",
        "    else:\n",
        "      count = 0\n",
        "    t += 1\n",
        "  if count == 3:\n",
        "    return True\n",
        "  \n",
        "  # Vertical\n",
        "  t = -min(2, j)\n",
        "  count = 0\n",
        "  while (t <= min(2, m-1-j) and count < 3):\n",
        "    if board[i,j+t] == p:\n",
        "      count += 1\n",
        "    else:\n",
        "      count = 0\n",
        "    t += 1\n",
        "  if count == 3:\n",
        "    return True\n",
        "  \n",
        "  # Main diagonal\n",
        "  t = -min(2, min(i, j))\n",
        "  count = 0\n",
        "  while (t <= min(2, min(n-1-i, m-1-j)) and count < 3):\n",
        "    if board[i+t,j+t] == p:\n",
        "      count += 1\n",
        "    else:\n",
        "      count = 0\n",
        "    t += 1\n",
        "  if count == 3:\n",
        "    return True\n",
        "\n",
        "  # Antidiagonal\n",
        "  t = -min(2, min(i, m-1-j))\n",
        "  count = 0\n",
        "  while (t <= min(2, min(n-1-i, j)) and count < 3):\n",
        "    if board[i+t,j-t] == p:\n",
        "      count += 1\n",
        "    else:\n",
        "      count = 0\n",
        "    t += 1\n",
        "  if count == 3:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "# Some pretty way of displaying the board in the terminal\n",
        "def pretty_print(board, n = 5, m = 5, symbols = \" XO\"):\n",
        "  for num in range(1, n+1):\n",
        "    print(\" \" + str(num) + \" \", end = \" \")\n",
        "  print()\n",
        "  for j in range(m):\n",
        "    for i in range(n):\n",
        "      print(\" \" + symbols[board[i,m-1-j]] + \" \", end = \" \")\n",
        "    print(\"\")\n",
        "# let's simulate a single game using pure random play, i.e. demonstrate an episode!\n",
        "def connect3():\n",
        "  S = iState() # initial board state\n",
        "  p = 1 # first player to move (other player is 2)\n",
        "  a = np.random.choice(np.where(S[:,-2] == 0)[0], 1) # first move is random\n",
        "  S = Action(S, int(a), p) # force first move to be random\n",
        "  p = getotherplayer(p) # other player's turn\n",
        "  while True:\n",
        "    # XX\n",
        "    # Look ahead til að athuga value á næstu 5 mögulegu stöðum\n",
        "    # hash-a stöðu, xor-a við allt sem er í boði og skoða gildi þeirrar stöðu\n",
        "    # taka það action sem fer í besta gildið, nema random með epsilon líkum\n",
        "\n",
        "    a = np.random.choice(np.where(S[:,-2]==0)[0],1) # pure random policy\n",
        "    if 0 == len(a): # check if a legal move was possible, else bail out\n",
        "      return 0, S # its a draw, return 0 and board\n",
        "\n",
        "    S = Action(S,int(a),p) # take action a and update the board state\n",
        "    if terminal(S, p, int(a), int(S[a,-1] - 1)):\n",
        "      return p, S # return the winning player and board\n",
        "    p = getotherplayer(p) # other player's turn\n",
        "  return 0, S # default is a draw\n",
        "\n",
        "# run demo for random play policy:\n",
        "winner, board = connect3()\n",
        "symbols = \" XO\"\n",
        "print(\" winner is '\", symbols[winner],\"' final board is:\\n\")\n",
        "pretty_print(board)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " winner is ' X ' final board is:\n",
            "\n",
            " 1   2   3   4   5  \n",
            "         O       O  \n",
            "         O       O  \n",
            " X       X       X  \n",
            " X       X   X   O  \n",
            " O       O   X   X  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FktNHPhJZ5mL"
      },
      "source": [
        "**Constructing value and action value tables using [Zobrist hashing](https://en.wikipedia.org/wiki/Zobrist_hashing):**\n",
        "\n",
        "Please do not modify how the zobTable is generated.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ8a3ubxIrZI",
        "outputId": "cc0f1e15-4871-4a7d-893c-95e1e88cfc08"
      },
      "source": [
        "print(np.where(board[:,-2] == 0)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adWrLjydTPp1"
      },
      "source": [
        "\"\"\"\n",
        "# let's all use the same zobTable, so we set the random seed\n",
        "np.random.seed(42)\n",
        "zobTable = np.random.randint(1,2**(5*5)-1, size=(5,5,3), dtype = np.uint32)\n",
        "# compute index from current board state\n",
        "def computeHash(board, n = 5, m = 5):\n",
        "  h = 0\n",
        "  for i in range(n):\n",
        "    for j in range(board[i,-1]):\n",
        "      h ^= zobTable[i,j,board[i,j]]\n",
        "  return h\n",
        "\"\"\"\n",
        "np.random.seed(42)\n",
        "zobTable = np.random.randint(1,2**64-1, size=(5,5,3), dtype = np.uint64)\n",
        "# compute index from current board state\n",
        "def computeHash(board, n = 5, m = 5):\n",
        "  h = np.uint64(0)\n",
        "  for i in range(n):\n",
        "    for j in range(board[i,-1]):\n",
        "      h ^= zobTable[i,j,board[i,j]]\n",
        "  return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGz4gIead0y8"
      },
      "source": [
        "maxHashValue = 2**(5*5)-2\n",
        "#V = np.zeros(maxHashValue, dtype=np.int16)\n",
        "V = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPVA4yFLvwvU",
        "outputId": "81964ac4-dbcb-4181-c03b-1749efd99e24"
      },
      "source": [
        "def nextHash(old_hash, i, j, p):\n",
        "  return old_hash ^ zobTable[i,j,p]\n",
        "\n",
        "def getVal(h):\n",
        "  if h in V:\n",
        "    return V[h]\n",
        "  return 0\n",
        "\n",
        "# Save your policy, PI to file, see folder icon on left hand side to download!\n",
        "#np.save(\"teymiX\", PI)\n",
        "#!ls\n",
        "\n",
        "upd = [0, 0, 0]\n",
        "def learn(greedy1 = False, greedy2 = False, pr = False):\n",
        "  S = iState() # initial board state\n",
        "  p = 1 # first player to move (other player is 2)\n",
        "  a = np.random.choice(np.where(S[:,-2] == 0)[0], 1) # first move is random\n",
        "  if pr:\n",
        "    print(int(a), end=\"\")\n",
        "  S = Action(S, int(a), p) # force first move to be random\n",
        "  p = getotherplayer(p) # other player's turn\n",
        "  h = computeHash(S)\n",
        "  b = pr\n",
        "  ct = 1\n",
        "  while True:\n",
        "    ct +=  1\n",
        "    a = np.where(S[:,-2] == 0)[0]\n",
        "    if 0 == len(a): # check if a legal move was possible, else bail out\n",
        "      V[h] = 1\n",
        "      if pr:\n",
        "        print(\"draw, moves = {}\".format(ct))\n",
        "      return 0 # its a draw, return 0 and board\n",
        "    vals = [getVal(nextHash(h, i, S[i,-1], p)) for i in a]\n",
        "    #vals = [V[nextHash(h, i, S[i,-1], p)] for i in a]\n",
        "    v = getVal(h)\n",
        "    if v == 0:\n",
        "      if -1 in vals:\n",
        "        upd[0] += 1\n",
        "        V[h] = 2\n",
        "      elif 0 not in vals and 1 not in vals:\n",
        "        upd[1] += 1\n",
        "        V[h] = -1\n",
        "      elif 0 not in vals:\n",
        "        upd[2] += 1\n",
        "        V[h] = 1\n",
        "    if (p == 1 and not greedy1) or (p == 2 and not greedy2):\n",
        "      # random policy\n",
        "      a = np.random.choice(a, 1)[0]\n",
        "    else:\n",
        "      # greedy policy\n",
        "      a = a[np.argmin(vals)]\n",
        "\n",
        "    S = Action(S, a, p) # take action a and update the board state\n",
        "    h1 = nextHash(h, a, S[a,-1] - 1, p)\n",
        "    if terminal(S, p, a, S[a,-1] - 1):\n",
        "      if (v == 0):\n",
        "        V[h] = 2\n",
        "        V[h1] = -1\n",
        "      if pr:\n",
        "        print(\"w = {}, moves = {}\".format(p, ct))\n",
        "        #pretty_print(S)\n",
        "      return p\n",
        "    if pr:\n",
        "      if b:\n",
        "        print(\", {}: \".format(a), end=\"\")\n",
        "        b = False\n",
        "      print(getVal(h), end=\" \")\n",
        "    h = h1 # Update the hash value\n",
        "    p = getotherplayer(p) # other player's turn\n",
        "\n",
        "for i in range(10):\n",
        "  upd = [0, 0, 0]\n",
        "  for j in range(10000):\n",
        "    learn()\n",
        "  print(\"{}: {}, {}, {}\".format(i, upd[0], upd[1], upd[2]))\n",
        "  for j in range(5):\n",
        "    learn(greedy1=True, greedy2=True, pr=True)\n",
        "w = 0\n",
        "l = 0\n",
        "for j in range(10000):\n",
        "  c = learn(greedy1=True)\n",
        "  if c == 1:\n",
        "    w += 1\n",
        "  elif c == 2:\n",
        "    l += 1\n",
        "print(\"Player 1 greedy:\\nWins: {}\\nLosses: {}\\n\".format(w, l))\n",
        "w = 0\n",
        "l = 0\n",
        "for j in range(10000):\n",
        "  c = learn(greedy2=True)\n",
        "  if c == 1:\n",
        "    w += 1\n",
        "  elif c == 2:\n",
        "    l += 1\n",
        "print(\"Player 2 greedy:\\nWins: {}\\nLosses: {}\\n\".format(l, w))\n",
        "w = 0\n",
        "l = 0\n",
        "for j in range(10000):\n",
        "  c = learn(greedy1=True, greedy2=True)\n",
        "  if c == 1:\n",
        "    w += 1\n",
        "  elif c == 2:\n",
        "    l += 1\n",
        "print(\"Both greedy:\\nPlayer 1 win: {}\\nPlayer 2 win: {}\".format(w, l))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 412, 86, 0\n",
            "2, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "4, 2: 2 -1 2 -1 2 -1 w = 2, moves = 8\n",
            "2, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "4, 2: 2 -1 2 -1 2 -1 w = 2, moves = 8\n",
            "3, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "1: 398, 82, 1\n",
            "3, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "1, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "0, 2: 2 -1 2 -1 2 -1 w = 2, moves = 8\n",
            "2, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "3, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "2: 391, 82, 0\n",
            "3, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "0, 2: 2 -1 2 -1 2 -1 w = 2, moves = 8\n",
            "1, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "4, 2: 2 -1 2 -1 2 -1 2 -1 w = 2, moves = 10\n",
            "1, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "3: 380, 91, 1\n",
            "4, 2: 2 -1 2 -1 2 -1 2 -1 w = 2, moves = 10\n",
            "0, 2: 2 -1 2 -1 2 -1 w = 2, moves = 8\n",
            "4, 2: 2 -1 2 -1 2 -1 2 -1 w = 2, moves = 10\n",
            "0, 2: 2 -1 2 -1 2 -1 w = 2, moves = 8\n",
            "3, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "4: 413, 93, 0\n",
            "0, 2: 2 -1 2 -1 2 -1 w = 2, moves = 8\n",
            "3, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "1, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "2, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "4, 2: 2 -1 2 -1 2 -1 2 -1 w = 2, moves = 10\n",
            "5: 403, 110, 0\n",
            "0, 2: 2 -1 2 -1 2 -1 w = 2, moves = 8\n",
            "3, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "3, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "4, 2: 2 -1 2 -1 2 -1 2 -1 w = 2, moves = 10\n",
            "2, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "6: 368, 97, 1\n",
            "1, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "3, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "4, 2: 2 -1 2 -1 2 -1 2 -1 w = 2, moves = 10\n",
            "0, 2: 2 -1 2 -1 2 -1 w = 2, moves = 8\n",
            "4, 2: 2 -1 2 -1 2 -1 2 -1 w = 2, moves = 10\n",
            "7: 382, 96, 0\n",
            "1, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "4, 2: 2 -1 2 -1 2 -1 2 -1 w = 2, moves = 10\n",
            "3, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "4, 2: 2 -1 2 -1 2 -1 2 -1 w = 2, moves = 10\n",
            "3, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "8: 315, 80, 0\n",
            "2, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "2, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "1, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "1, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "0, 2: 2 -1 2 -1 2 -1 w = 2, moves = 8\n",
            "9: 371, 95, 0\n",
            "3, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "2, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "0, 2: 2 -1 2 -1 2 -1 w = 2, moves = 8\n",
            "1, 0: -1 2 -1 2 -1 2 -1 w = 1, moves = 9\n",
            "4, 2: 2 -1 2 -1 2 -1 2 -1 w = 2, moves = 10\n",
            "Player 1 greedy:\n",
            "Wins: 9848\n",
            "Losses: 152\n",
            "\n",
            "Player 2 greedy:\n",
            "Wins: 8295\n",
            "Losses: 1705\n",
            "\n",
            "Both greedy:\n",
            "Player 1 win: 5919\n",
            "Player 2 win: 4081\n"
          ]
        }
      ]
    }
  ]
}